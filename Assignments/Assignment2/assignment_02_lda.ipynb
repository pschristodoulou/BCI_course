{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear discriminant analysis\n",
    "\n",
    "> A serious attempt at all the assignments is mandatory to grant access to the final exam. Refer to the course manual for more details (section *Overview* on Brightspace). \n",
    "\n",
    "> Please add today's topic to your knowledge graph.\n",
    "\n",
    "**Learning goals:**\n",
    "- Understand and be able to implement and use LDA;\n",
    "- Understand assumptions and limitations of LDA;\n",
    "- Be able to provide solution to common issues of LDA.\n",
    "\n",
    "**Solutions file:**\n",
    "\n",
    "For this assignment, a solutions file will be released after the deadline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: train LDA\n",
    "In the first exercise, you will implement LDA from scratch using plain numpy. We will later train and test it with the Iris dataset, and compare it to the implementation from the \"sklearn\" library.\n",
    "1. Provide the equations to train the weights and bias of LDA in LaTeX. (You can use LaTeX in Markdown by surrounding your formula with \\$\\$); \n",
    "1. Write the function `train_lda(X, y)` that accepts the data $X$ of dimensionality $N_{samples} \\times D_{features}$ and the labels $y$, a vector of $N_{samples}$ containing integer class labels. The function should output the weights and bias. Note, we assume a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: apply LDA\n",
    "The next step is to implement the routine to apply LDA to new data (i.e., validation/test data). \n",
    "1. Provide the equations to apply LDA to new data using the weights and bias in LaTeX;\n",
    "1. Write a function `apply_lda(X, weights, bias)` that accepts the weights and bias to classify data $X$ of dimensionality $N_{samples} \\times D_{features}$. It should output predicted labels, one for each sample in $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: classify the Iris dataset\n",
    "Now it is time to test your implementation. For this we use the well-known Iris dataset. We provide some code below to download this data from the \"pandas\" library using `datasets.load_iris()`. Many more standard datasets exist there for quick testing and benchmarking. Pandas uses so called 'dataframes' that are easily interpreted by \"seaborn\", that has a nice built-in function `pairplot()` to visualize the features. For this assignment, we will restrict the dataset to only two classes.\n",
    "\n",
    "Your tasks:\n",
    "1. Train and apply your LDA and compute the classification accuracy.\n",
    "1. Train and apply the LDA from sklearn (`LDA()`), and compare its classification accuracy to yours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris dataset and select 2 classes\n",
    "iris = datasets.load_iris()\n",
    "labels = [1, 2]\n",
    "idx = np.logical_or(iris.target == labels[0], iris.target == labels[1])\n",
    "iris.data = iris.data[idx, :]\n",
    "iris.target = iris.target[idx]\n",
    "\n",
    "# Make a pandas dataframe\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df[\"species\"] = iris.target_names[iris.target]\n",
    "\n",
    "# Plot data\n",
    "sns.pairplot(df, hue=\"species\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "print(\"Number of features: \", X_train.shape[1])\n",
    "print(\"Number of train examples: \", X_train.shape[0])\n",
    "print(\"Number of valid examples: \", X_valid.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: preprocess features\n",
    "Sometimes, some of the features clearly violate the **linear separability** assumption made by LDA. In that case, features can be pre-processed by applying a given function to each feature, which yields a Generalized Linear Discriminant analysis:\n",
    "\n",
    "$$ y = \\sum_i^D w_i f_i(\\mathbf{x}_i) $$ \n",
    "\n",
    "We provide a dataset below, please inspect it.\n",
    "\n",
    "Your tasks:\n",
    "1. Which LDA assumption(s) are violated by the provided dataset?\n",
    "1. In which way can the feature(s) be preprocessed in order to improve the performance? Hint: Think of polynomials, trigonometric functions, logarithms, exponential functions, etc.;\n",
    "1. Apply your preprocessing idea to the data;\n",
    "1. Visualize the preprocessed data;\n",
    "1. Classify the preprocessed data using sklearn's `LDA()`. Did it improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) load data\n",
    "ds_data = 'data/non-lin_train.data'\n",
    "ds_labels ='data/non-lin_train.labels'\n",
    "X = np.loadtxt(ds_data)\n",
    "y = np.loadtxt(ds_labels)\n",
    "n_samples = y.size\n",
    "\n",
    "# (2) split into training and validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# (3) scatter-plot data with corresponding labels\n",
    "plt.figure()\n",
    "plt.scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1] ,color='b')\n",
    "plt.scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1], color='g')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.grid()\n",
    "\n",
    "# (4) classify un-processed data\n",
    "clf = LDA()\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_valid, y_valid) * 100\n",
    "print('Accuracy validation: {:.2f}%'.format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Exercise 5: extract features\n",
    "Below we provide another dataset. There appears to be some exploitable structure in this data, but the LDA is not directly able to capture this.\n",
    "\n",
    "Your tasks:\n",
    "1. Which LDA assumption(s) are violated by the provided dataset?\n",
    "1. In what way can the existing features be combined in order to get a proper dataset? **Hint:** Try to think of it in a 3D way: How would you add another dimension such that the 2 classes can be separated?\n",
    "1. Implement your additional feature that combines the existing features;\n",
    "1. Visualize the new feature using a histogram;\n",
    "1. Calculate the performance of LDA using this additional feature and see if you can improve upon the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) load data\n",
    "ds_data = 'data/circles_train.data'\n",
    "ds_labels ='data/circles_train.labels'\n",
    "X = np.loadtxt(ds_data)\n",
    "y = np.loadtxt(ds_labels)\n",
    "n_samples = len(y)\n",
    "\n",
    "# (2) split into training and validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# (3) scatter-plot data with corresponding labels\n",
    "plt.figure()\n",
    "plt.scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1] ,color='b')\n",
    "plt.scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1], color='g')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.grid()\n",
    "\n",
    "# (4) classify un-processed data\n",
    "clf = LDA()\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_valid, y_valid) * 100\n",
    "print('Accuracy validation: {:.2f}%'.format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Exercise 6: other LDA-like algorithms\n",
    "Below we provide another dataset, that again is problematic for standard LDA.\n",
    "\n",
    "Your tasks:\n",
    "1. What LDA assumption(s) are violated by the next dataset?\n",
    "1. What would be an optimal decision boundary? Optional: Find out which method would provide an optimal decision boundary. **Hint:** It is slightly more general than the LDA algorithm;\n",
    "1. Implement this improvement and verify whether it indeed improves classification of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) load data\n",
    "ds_data = 'data/unbalanced_train.data'\n",
    "ds_labels ='data/unbalanced_train.labels'\n",
    "X = np.loadtxt(ds_data)\n",
    "y = np.loadtxt(ds_labels)\n",
    "n_samples = len(y)\n",
    "\n",
    "# (2) split into training and validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# (3) scatter-plot data with corresponding labels\n",
    "plt.figure()\n",
    "plt.scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1] ,color='b')\n",
    "plt.scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1], color='g')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.grid()\n",
    "\n",
    "# (4) classify un-processed data\n",
    "clf = LDA()\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_valid, y_valid) * 100\n",
    "print('Accuracy validation: {:.2f}%'.format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: Apply LDA to EEG data\n",
    "Now you will try a simple decoding on EEG data. For this, we will make use of one of mne's standard data sets, which you will already know from assignment 1 - but we just load a version resampled to `30Hz`.\n",
    "\n",
    "The data we load is the so called `raw` data, which we will slice to epochs depending on markers relative to the start of the recording of the raw file. Each epoch should range from -200ms to +800ms around the epoch start marker. Of course you could just make use of `mne`'s build in functions. But for now please operate on the plain numpy array of the raw data. This will ensure, that you are aware of the notion of `epoch` vs `raw` data.\n",
    "\n",
    "We need this epoch structure as EEG experiments are usually designed to produce one label per epoch. Hence an epoch is our basic \"record\" unit.\n",
    "\n",
    "**Question**:\n",
    "1. Slice the raw data to epochs.\n",
    "1. After step 1. your data should be in shape of [n_epochs x n_channels x n_times]. The next step is to stack the channel dimension in order to be able to use the data in a standard `sklearn` LDA classifier. Transform the epoched data to [n_epochs x n_channels * n_times]\n",
    "1. Use the first 100 epochs to train an LDA classifier and report the accuracy of classifying\n",
    "   the left over epochs as test set.\n",
    "1. *Optional*: Why will the classifier just perform very poorly in terms of accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data and the classifier\n",
    "\n",
    "# the raw data\n",
    "raw = mne.io.read_raw('./data/sample_audvis_rsampl30Hz_raw.fif')\n",
    "Xraw = raw.get_data()\n",
    "\n",
    "# markers == labels (not always the case that all markers are labels, but its valid here)\n",
    "mrks = np.load('./data/events.npy', allow_pickle=True)\n",
    "mp = {1: 'left_auditory', 2: 'right_auditory'}\n",
    "mrks_t = mrks[:, 0]\n",
    "y = [mp[e] for e in mrks[:, 1]]\n",
    "\n",
    "# the classifier\n",
    "clf = LDA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 0: Who did what?\n",
    "Please provide a short description on who contributed what to your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "bae39ce3edb1180dfc3794c6b6a6cb1354ac6855e2f7c16c3eda95d583036c65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
